%chktex-file 36
%chktex-file 23
%chktex-file 10
%chktex-file 17
%chktex-file 9
\documentclass[computational_mathematics.tex]{subfiles}

\begin{document}

%%%%%%%%%%%%%%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~%%%%%%%%%%%%%%%
\section{27th of September 2018 --- A. Frangioni}
%%%%%%%%%%%%%%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~%%%%%%%%%%%%%%%


\begin{definition}[Minimizing sequence]
Let us consider the \textbf{minimum problem} defined in \Cref{def:min_prob}:

\[
  (P) \qquad f_* = \min \{f(x)~:x \in X\}
\]

  we term \textbf{minimizing sequence} a sequence that gets closer to the optimal value: $\{x_i\}$ s.t.~$\{f(x_i)\} \to f_*$.
\end{definition}

It goes without saying that we would like to avoid minimizing sequences that do not lead to an optimum.

As an example, consider

  $\min \{x~:~x \in \R \wedge x > 0\} ~ \{x_i = 1/i\}$, where $\{f(x_i)\} \to 0$, but it is not an optimum or 

  $\min \{1/x~:~x \in \R \wedge x > 0\} ~ \{x_i = i\}$, where $\{f(x_i)\} \to 0$, but it is not an optimum.\\
  
We want \emph{conditions} that ensure $\{f(x_i)\} \to f_* \Rightarrow \{x_i\}\to x_* \in X \quad optimal \, solution$.

\begin{definition}[Interior and border of a set]
  Given $S \subseteq \R^n$, we say that $x \in int(S)$ ($x$ is an \textbf{interior point}) if $\exists r > 0$ s.t. $\mathcal{B}(x,~r) \subseteq S$.

  On the other hand, we term \textbf{border points} those $x \in \partial(S)$ such that $\forall r > 0~\exists y,z \in \mathcal{B}(x,~r)$, where $y \in S \wedge z \notin S$.
  Intuitively, a point $x$ lies on the border if, all the points in the ball centered in $x$ lie for a half inside the set $S$ and for the other half outside. 
\end{definition}

Notice that a point on the boundary is not necessarily inside the ball, in that case we talk about \textbf{open set} (a set which is identical to its interior: $S = int(S)$).

\begin{definition}[Closure of a set]
  Let $S \subset \R^n$ we term \textbf{closure} of $S$ the set $cl(S) = int(S) \cup \partial S$.
\end{definition}

\begin{definition}[Closed set]
  We say that a set $S \in \R^n$ is \textbf{closed} if it coincides with his closure: $S=cl(S)$.

  Equivalently, a set is termed \textbf{closed} if its complementary is open: $\R^n \setminus S$.
\end{definition}

It is interesting to notice that the cases of functions that lead to minimizing sequences that do not bring to an optimum are all defined in open sets.

Notice that there are sets that are both open and closed, for example $R^n$.

\begin{definition}[Bounded set]
  Let $S \subseteq \R^n$. We say that $S$ is \textbf{bounded} if $\exists r > 0$ such that $S \subseteq \mathcal{B}(0,r)$.
  
  Intuitively, a bounded set does not go to $\infty$.
\end{definition}

\begin{definition}[Compact set]
 Let $S \subseteq \R^n$. We term $S$ \textbf{compact} if it is both closed and bounded.
\end{definition}

\begin{definition}[Accumulation point]
  Let $\{x_i\}$ be a sequence. $x$ is an \textbf{accumulation point} if $\exists~\{x_{n_i}\}$ subsequence of $\{x_i\}$ such that $\{x_{n_i}\} \to x$ $\equiv~\lim \inf_{i \to \infty} d(x_i,~x) = 0$.
\end{definition}

\begin{proposition}
  Let $S$ be a compact set and let $\{x_i\} \subseteq S$ minimizing sequence. (Bolzano-Weierstrass) $\{x_i\}$ has an \textbf{accumulation point} $x \in S$, thus the limit of the sequence has to be a feasible solution.
\end{proposition}

Why did we say \emph{feasible} but not \emph{optimal}? If the function is not continuous (cfr. \Cref{fig:27set0}) it may happen that the sequence is minimizing, but the limit is not the optimum.

\addpic{0.5}{pics/27set/1.png}{Case of non-continuity of the objective function in the border point $(0, 0)$.}{fig:27set0}

\begin{definition}[Domain]
Let $f : D \to \R$. We term $D$ \textbf{domain}: $D = \text{dom}(f)$.
\end{definition}

In this course we will not take into account the domain of functions, because we can make functions defined in the whole space as follows:

$f : \R^n \to \bar{\R}$, where $f(x) = \infty$ for $x \notin D$.

\begin{definition}[Graph and epigraph]
  Let $f: \R^n \to \R$. We term \textbf{graph} $\text{gr}(f) = \{(f(x),~x)~:~x \in \text{dom}(f)\}$.

  On the other hand, we term \textbf{epigraph} $\text{epi}(f) = \{(v,~x)~:~x \in \text{dom}(f)~\wedge~v \geq f(x)\}$.
\end{definition}
  A graphic example of epigraph is displayed in \Cref{fig:27set1}.

\addtwopics{0.43}{pics/27set/f2.pdf}{0.43}{pics/27set/f3.pdf}{On the left-hand side the graph of the function $f(x)$, while on the right-handed side the epigraph of such function.}{fig:27set1}

\begin{definition}[Level and sublevel set]
  Let $f: \R^n \to \R$. We term \textbf{level set} $L(f,v) = \{x \in \text{dom}(f)~:~f(x) = v\}$.

  On the other hand, we term \textbf{sublevel set} $S(f,v) = \{x \in \text{dom}(f)~:~f(x) \leq v\}$.
\end{definition}
  
  Intuitively, the level sets are projections of the points of the domain and they are used in order to ``look'' at the function even if we are working in $\R^n$.

  A graphic example of level set is displayed in \Cref{fig:27set2}.

  \addtwopics{0.43}{pics/27set/f4.pdf}{0.43}{pics/27set/f5.pdf}{On the left-handed side of the figure, the level set of the function $f$, while on the right-hand side the sublevel set of such function.}{fig:27set2}

\subsection{Continuity}

\begin{definition}[Continuity]
  Let $f: \R^n \to \R$. We say that $f$ is \textbf{continuous} if $\forall \varepsilon > 0 \;  \exists \, \delta > 0$ such that $\abs{f(y) - f(x)} < \eps~\forall y \in \mathcal{B}(x ,~\delta)$.
\end{definition}

Notice that if $f, g$ continuous at $x$ then:

\begin{enumerate}
  \item $f+g$, $f \cdot g$ continuous at $x$
  \item $\max\{f,~g\}$ and $\min\{f,~g\}$ continuous at $x$
  \item $f \circ g$ $\equiv$ $f(g(\cdot))$ continuous at $x$
\end{enumerate}

\begin{theorem}[Intermediate value]
Let $f : \R \to \R$. $f$ is continuous on  $[a,~b]$ if $\forall v$ $\min \{f(a),~f(b)\} \leq v \leq \max \{f(a),~f(b)\}~\exists~c \in [a,~b]$ such that $f(c) = v$.
\end{theorem}


\begin{theorem}[Weierstrass extreme value theorem]
Let $X \subseteq \R^n$ be a compact set and let $f$ continuous on $X$. Then $(P)$ has an optimal solution.

Equivalently, let $X \subseteq \R^n$ compact and let $f$ continuous on $X$. Then all accumulation points of any minimizing sequence are optima and \emph{there is at least one}.
\end{theorem}

\begin{definition}[Lipshitz continuity]
Let $f: \R^n \to \R$. We term $f$ \textbf{Lipschitz continuous} (L.c.) on $S \in \R^n$ if $\exists L > 0$ such that
       \[
         \abs{f(x) - f(y)} \leq L \norm{x - y}~ \forall x, y \in S
       \]
More generally, $f$ is \textbf{globally Lipshitz continuous} if $S = \R^n$ and it is \textbf{locally Lipshitz continuous} if at $x$ $\exists~\varepsilon > 0 ~S = \mathcal{B}(x,~\varepsilon)$. It's a stronger form of continuity.
\end{definition}

Notice that the $L$ constant value depends on $S$. The wider the set the smaller $L$.

\begin{proposition}
Let $f: \R^n \to R$. On a compact set $S \in \R^n$ if $f$ is continuous then it is Lipshitz continuous.
\end{proposition}

\begin{definition}[Lower-upper semi-continuous]
Let $f: \R^n \to \R$ $f$ is \textbf{lower}[upper] \textbf{semi-continuous} (l.[u.]s.c.) at $x$ if
  \[
    \textstyle
    \{ \, x_i \, \} \to x \;\; \Longrightarrow \;\;
    f(x) \leq \lim \inf_{i \to \infty} f(x_i)
    \;\; [ \, f(x) \geq \lim \sup \ldots \, ]
  \]

  Equivalently, $\lim \inf_{y \to x} f(y) \geq f(x)$, $\lim \sup_{y \to x} f(y) \leq f(x)$.\\
\end{definition}

\subsection{Derivatives}

In this section we address the problem of inferring information on a complicated function arround a certain value $\bar{x}$ using very simple functions, that provide information which is reliable close to the point we are studying.
Those functions are called ``derivatives''.

It goes without saying that it is not possible to compute such simple representation in any kind of point.

\begin{definition}[Left and right derivative]
  Let $f: \R \to \R$. We term \textbf{left derivative} $f'_{-}(x) = \lim_{t \to 0_{-}} [f(x + t) - f(x)] / t$.
  
  On the other hand, \textbf{right derivative} $f'_{+}(x) = \lim_{t \to 0_{+}} [f(x + t) - f(x)] / t$.
\end{definition}

\begin{definition}[Differentiable]
  Let $f:\R \to \R$. We say that $f$ is \textbf{differentiable} at $x \in dom(f)$ if $f'_-(x) = f'_+(x)$ $\Leftarrow$ they $\exists$.
\end{definition}

\begin{proposition}
  Let $f: \R \to \R$ and differentiable in $x \in dom(f)$ then $f$ is continuous in $x$. 
\end{proposition}


\begin{theorem}[Mean value theorem]
$f : \R \to \R$ continuous on $[a, b]$ and differentiable on $(a,b)$ then $\exists \, c \in (a, b)$ s.t. $f'(c) = ( \, f(b) - f(a) \, ) / (b - a)$.
\end{theorem}

\begin{theorem}[Rolle's theorem]
Let $f: \R \to \R$. $f(a) = f(b)$ then $\exists~c \in (a, b)$ s.t.~$f'(c) = 0$
\end{theorem}

\begin{corollary}
In the same hypothesis of Rolle's theorem, let $a$ and $b$ consecutive roots of $f$. Then $f'(a)$ and $f'(b)$ have opposite sign.
\end{corollary}

\subsubsection{Multivariate differentiability}

\begin{definition}[Partial derivative]
Let $f : \R^n \to \R$. We term \textbf{partial derivative} of $f$ w.r.t.~$x_i$ at $x \in \R^n$ as
  \[
  \frac{\partial f}{\partial x_i}(x) = \lim_{t \to 0} \frac{f(x_1,~, \ldots,~x_{i-1},~x_i + t,~x_{i+1},~\ldots,~x_n) - f(x)}{t}
  \]
       
In other words, it is just $f'(x_1,\dots,x_{i-1},x,x_{i+1},\dots,x_n$), treating $x_j$ for $j \neq i$ as constants.
\end{definition}

\begin{definition}[Gradient]
Given $f : \R^n \to \R$. We term \textbf{gradient} of $f$ the vector of all the partial derivatives.
\end{definition}

\begin{definition}[Directional derivative]
  Let $f : \R^n \to \R$. We term \textbf{directional derivative} of $f$ in point $x \in dom(f)$ along direction $d \in \R^n$
  \[
    \frac{\partial f}{\partial d}(x) :=	\lim_{t \to 0} \frac{f(x + td ) - f(x)}{t}
  \]
\end{definition}

In a multivariate space it is not possible to assure differentiability checking if the directional derivatives are equal, because there is an infinite number of different directions.

We are now ready to introduce the notion of multivariate differentiability.

\begin{definition}[Differentiable]
Let $f: \R^n \to \R$. We say that $f$ is \textbf{differentiable} at $x$ if $\exists$ a linear function $\phi(h) = \ps{c}{h} + f(x)$ s.t.
  \[
    \lim_{\norm{h} \to 0} \frac{\norm{f(x + h) - \phi(h)}}{\norm{h}}= 0
  \]
  The intuition here is that the linear function should approximate $f$ pretty well around $x$.
\end{definition}

The gradient is the direction on which the function increases more rapidly, while the opposite of the gradient suggests the direction on which the function decreases most.

\begin{proposition}
Let $f : \R^n \to \R$ differentiable at $x$. Then $f$ is locally Lipschitz continuous at $x$.
\end{proposition}

\begin{corollary}
Let $f : \R^n \to \R$ differentiable at $x$. Then $f$ is continuous at $x$.
\end{corollary}

Notice that the convers does not hold.

\begin{proposition}\label{prop:27set1}
Let $f : \R^n \to \R$ and let us assume $\exists \delta > 0$ s.t.~$\forall i~\frac{\partial f}{\partial x_i}(y)$ is continuous $\forall y \in \mathcal{B}(x, \delta)$.

Then $f$ differentiable at point $x$.
\end{proposition}

Notice that the converse of \Cref{prop:27set1} does not hold either.

We are now ready to introduce a class of functions that allows good results for optimization: $\C{1} := \nabla f(x)$ continuous.

Let $f \in \C{1}$, then $f$ is differentiable everywhere and also continuous everywhere.

\Cref{fig:27set3}, \Cref{fig:27set4} and \Cref{fig:27set5} picture some functions which are not differentiable in the minimum.

\addpic{0.35}{pics/27set/nondiff1.png}{The function $f(x_1,x_2) = \norm{[x_1,x_2]} = |x_1| + |x_2|$ has some kinks.}{fig:27set3}

\addpic{0.35}{pics/27set/nondiff2.png}{The function $f(x_1,x_2) = \frac{{x_1}^2 x_2}{{x_1}^2 + {x_2}^2}$ may be put to $0$ in $(0, 0)$ for continuity, but it is still not differentiable in $(0, 0)$ although the function admits directional derivatives in $(0, 0)$.}{fig:27set4}

\addpic{0.35}{pics/27set/nondiff4.png}{The function $f(x_1,x_2) = {\left( \frac{{x_1}^2 x_2}{{x_1}^4 + {x_2}^2} \right)}^2$ is not continuous in $0$. There are some directions that lead to the limit $0$, while there are some other directions (the parabolas above) that do not lead to value $0$.}{fig:27set5}

\begin{definition}[First order model]
  Let $f: \R^n \to \R$ and let $x \in dom(f)$. We term \textbf{first order model} of $f$ at point $x$ 
  \[
    L_x(y) = \nabla f(x) (y - x) + f(x)
  \]
\end{definition}

\begin{proposition}
  Let $f: \R^n \to \R$ and let $x \in dom(f)$ such that $f$ is differentiable at $x$. Then $(L_x, f(x)) \perp S(f, f(x)) \perp \nabla f(x)$.
\end{proposition}

Geometrically speaking, we can observe that a function is smooth whenever its levelsets are smooth.
\end{document}
