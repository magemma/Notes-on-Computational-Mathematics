%chktex-file 36
\documentclass[computational_mathematics.tex]{subfiles}

\begin{document}

%%%%%%%%%%%%%%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~%%%%%%%%%%%%%%%
\section{24th of October 2018 --- A. Frangioni}
%%%%%%%%%%%%%%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~%%%%%%%%%%%%%%%

\subsection{Gradient method for non quadratic functions}
We want to move from quadratic functions to wider families of functions.

\recap{The step size $\alpha$ in the quadratic case is defined as follows: $\alpha = \frac{\sqrnorm{d}}{\tr{d}Qd}$}

We would like to find a more general form for the step size, which doesn't depend on the fact that the function is quadratic.

The algorithm for finding local minima of non quadratic functions has the same structure of the one used for quadratic ones, i.e.~first compute the direction of the step and then compute its size.

We will see that, differently from the quadratic case (where the gradient was $\nabla f(x) = Qx + q$) computing the gradient in this more general case isn't easy at all.

We may recall from last lecture that the proof of the orthogonality of the gradient doesn't depend on the quadratic nature of our functions, so it works in this case too.

\subsubsection{How fast does it converge?}
Given \Cref{alg:24ottnonQuad} for finding minima of quadratic functions (that differs from the one provided for quadratic ones for the step size) we would like to understand how fast the convergence is.

\algo{alg:24ottnonQuad}{Pseudocode for non quadratic functions local minimum detection.}{
    \Procedure{\bf SDQ}{$f, x, \varepsilon$}
      \While{($\norm{\nabla f(x)} > \varepsilon$)}
        \State~$d \gets - \nabla f(x)$;
        \State~$\alpha \gets \frac{\sqrnorm{d}}{(\tr{d} Q d)}$;
        \State~$x \gets x + \alpha d$;
      \EndWhile%
    \EndProcedure%
}

\begin{theorem}
  Let $f$ be a function in $C^2$ and let $x_*$ be a local minimum for $f$ s.t.~$\nabla^2 f(x_*)~\succ~0$ (which means that the Hessian matrix is strictly positive definite):
       \[
       \{ \, x^i \, \} \to x_*
        \Longrightarrow \{ \, f(x^i) \, \} \to f(x_*)
      \]
        linearly, with same $R$ as the quadratic case, depending on
       $\lambda_1$ and $\lambda_n$ of $\nabla^2 f(x_*)$
\end{theorem}

This theorem means that if the function is differentiable and the Hessian is strictly positive definite then when getting closer and closer to the minimum, the function is more and more similar to a quadratic function.

This similarity is a good new, since we can use the same methods of the quadratic case, but, as we recall from the previous lecture, we must pay attention to \textbf{conditioning}.

At this point we need to work on finding the local minimum of the one dimensional function $\varphi^{i}$, s.t.
\[
  \varphi^{i}(\alpha) = f(x^{i} + \alpha d^{i}),
\]

where $d^{i} = - \nabla f(x^{i})$.

Let's omit the $i$, since we are concentrating on a single iteration.

We are interested in finding a $\alpha^{*}$ such that $ \varphi'(\alpha^{*}) = 0$

\begin{example}
  Let's suppose we are in $\R^{2}$ and $f(x, y) = x^{2} e^{y}$. We can differentiate $F$ and $\nabla f(x, y) = (2x e^{y}, x^{2} e^{y})$.

  At the $i$-th iteration $(x, y) = (1,0)$, so $\nabla f(1,0) = (2, 1)$. Now $x(\alpha) = (1, 0)- \alpha (2, 1) = (1 -2 \alpha, 0 - \alpha)$.

At this point we obtain $\varphi(\alpha) = f(x(\alpha)) = {(1-2 \alpha)} ^{2} e^{- \alpha}$.
\end{example}


\todo{Chi Ã¨ $x(\alpha)$?}

It's hard to find the roots of this function. The points we can find are not $\varphi '(\alpha) = 0$, but instead $\abs{\varphi ' (\alpha) \le \varepsilon'}$, where the meaning of $\varepsilon$ is bounding the directional derivative to be small.

\begin{proposition}\label{24ottps}
  Let $\varphi: \R \to \R$, such that $\varphi(\alpha) = f(x^{i} + \alpha d^{i})$, $\varphi'(\alpha) =\ps{\nabla f(x^i + \alpha d^i)}{d}$.
\end{proposition}
\begin{proof}
  TODO:~using the \textbf{chain rule}: $f : \R^m \to \R^k$, $g : \R^n \to \R^m$, $h : \R^n \to \R^k$ such that $h(x) = f(g(x)) \Rightarrow~\mathbf{J h(x) = J f(g(x)) \cdot J g(x)}$

  Obs: $J f \in \R^{ k \times m }$, $J g \in \R^{ m \times n }$ and $J h \in \R^{ k \times m } \cdot \R^{ m \times n }  = \R^{ k \times n }$.
\end{proof}


\begin{proposition}
We claim that $\varepsilon' = \varepsilon$. 
\end{proposition}
\begin{proof}
We want to find the relationship between the two parameters $\varepsilon$ and $\varepsilon '$. Assuming that we've got a black box that finds $\alpha$, given $\varepsilon '$, we are interested in computing $\varepsilon '$.

  \textbf{Key idea:} Normalization of the direction.

  We may normalize the direction of movement $d^{i}$ without perturbing the behaviour of the algorithm: $d^i = - \frac{\nabla f(x^i)}{\norm{\nabla f(x^i)}}$. Note that we're not worried of dividing by the norm of the gradient, since if it gets $0$ we have already stopped the procedure.

In this new context $\norm{d^i} = 1$ and 
\begin{equation}
  \begin{split}
    \varphi'(0) &= \frac{\partial f}{\partial d}(x)\\
    \text{(From \Cref{24ottps})} & = \ps{\nabla f(x)}{d}\\
    & = \ps{\nabla f(x)}{\frac{- \nabla f(x)}{\norm{\nabla f(x)}}}\\
    & = -\frac{<\nabla f(x) , \nabla f(x) >}{\norm{\nabla f(x)}}\\
    & = - \frac{{\norm{\nabla f(x)}}^{2}}{\norm{\nabla f(x)}}\\
    & = -\norm{\nabla f(x^i)}
    \end{split}
  \end{equation}


 $\abs{\varphi'(\alpha^i)} =
        \lvert \ps{\nabla f(x^{i+1})}{d^{i}} \rvert =
        \abs{\ps{\nabla f(x^{i+1})}{-\frac{\nabla f(x^{i})}{\norm{\nabla f(x^i)}}}}$

 Hence, if $\{x^{i}\} \to x$
  \begin{equation}
      \lim_{i \to \infty} \abs{\ps{\frac{\nabla f(x^i)}{\norm{\nabla f(x^i)}}}{\nabla f(x^{i+1})}} 
       = \ps{\frac{\nabla f(x)}{\norm{\nabla f(x)}}}{\nabla f(x)}
       = \norm{\nabla f(x)} \leq \varepsilon
  \end{equation}
 Since $\norm{\nabla f(x^i)} > \varepsilon$ we have the thesis.
\end{proof}

Per each phase the new epsilon is obtained $\varepsilon \gets \varepsilon \norm{\nabla f(x^i)}$.

If we can prove that the algorithm is converging we know when to stop.

This convergence isn't the perfect mathematical convergence, since $\varepsilon \ne 0$, because the line search will never terminate.


\subsubsection{Exact line search, first orderd approach}
We want to find the minimum points of $\varphi$, which corresponds to points where the first order derivative is zero and it goes from negative to positive. Since we are talking about numerical algorithms we are going to stop a little before the minimum is reached.

\textbf{Key idea:} We would like to reduce the range in which performing the search, at each step.

How can we be sure that in a given range there is a point where the derivative is $0$? Rolle's theorem, as shown in \Cref{fig:24ott1}.

\addtwopics{0.4}{pics/24ott/1.png}{0.4}{pics/24ott/2.png}{First, we restrict from $\R$ to $[x_{1}, x_{2}]$, then double $\alpha$ until the derivative is greater than $0$}{fig:24ott1}

Since the gradient is continuous the directional derivative is continue, so $\varphi$ is continuous (the scalar product is continuous).

Actually, we only need to find where the derivative is positive, because the $0$ of the derivative is between the previous value and this point.

The algorithm is the following:

\algo{alg:24ottELS1}{First algorithm for exact line search}{
  \State~$\bar{\alpha} \gets x_{1}$; \#or whatever value $>0$
    \While{($\varphi'(\bar{\alpha}) < 0$)}
      \State~$\bar{\alpha} \gets 2 \bar{\alpha}$; \#or whatever factor $>1$
    \EndWhile%
}

We'll stop when $\alpha < -{10}^{308}$, which is the smallest value for a double, since we will get a numerical error and stop.

Works if $\varphi$ \textbf{coercive}:
       $\lim_{\alpha \to \infty} \varphi( \, \alpha \, ) = \infty$
       (ex.~$f$ strongly convex)

\begin{exe}
Build an example where $\bar{\alpha}$ exists but it is not found by this algorithm.
\end{exe}
\textbf{Solution:} The function changes its derivative in a range between $\alpha$ and $2 \alpha$.


An alternative to the algorithm presented above may be the bisection algorithm, which follows.

\algo{alg:24ottBS}{Bisection algorithm}{
\Procedure{LSBM}{($\varphi', \bar{\alpha}, \varepsilon$)}
  \State~$\alpha_- \gets 0$;
  \State~$\alpha \gets \alpha_+$;
  \State~$\alpha_{+} \gets \bar{\alpha}$;
  \While{($\abs{\varphi'(\alpha)} > \varepsilon$)}
    \State~$\alpha \gets (\alpha_{+} + \alpha_{-}) 2$;
    \If{($\varphi'(\alpha) < 0$)}
      \State~$\alpha_- \gets \alpha$;
    \Else%
      \State~$\alpha_+ \gets \alpha$;
    \EndIf%
  \EndWhile%
\EndProcedure%
}


We would like to improve this algorithm too, finding a better point in the middle than the middle point.

\addpic{0.5}{pics/24ott/3.png}{The information we have about function $\varphi$}{fig:24ott3}

We may use the information we have about the function, since we know $\varphi(\alpha^{-})$, $\varphi ' (\alpha^{-})$, $\varphi(\alpha^{-})$ and $\varphi ' (\alpha^{-})$.

At this point we can write a model ($m(\alpha) = a {\alpha}^{2} + b \alpha + c$) and specialize it with the information we have, via computing a linear system:
\[
\begin{cases}
  a {(\alpha^{-})}^{2} + b (\alpha^{-}) + c = \varphi(\alpha)\\
  a {(\alpha^{-})}^{2} + b (\alpha^{-}) + c = \varphi(\alpha)\\
  2a \alpha^{-} + b = \varphi'(\alpha^{-})\\
  2a \alpha^{+} + b = \varphi'(\alpha^{+})
\end{cases}
\]

Then we look for the stationary point of this function and that's the ball where I'm likely to find the root of the derivative.

We can say something more, since the following fact holds:

\begin{proposition}\label{fact:24ott3}
Let $\varphi \in C^{{3}}$, then quadratic interpolation has convergence of order $1 < p < 2$ (superlinear)
\end{proposition}

In \Cref{fig:24ott4} we can observe a situation in which the hypothesis of \Cref{fact:24ott3} aren't satisfied.

\addpic{0.5}{pics/24ott/4.png}{If the function isn't $C^3$ and one derivative is very big, then the range doesn't shrink much.}{fig:24ott4}

We would like to modify the formula to have at least linear convergence.

We can ensure to move not to close to one of the extremes, for example more than $10\%$.

Another idea is, since we have four equations, to build a cubic function, although the operation is very long. In this case the convergence get quadratic, which is better than linear.

\end{document}
