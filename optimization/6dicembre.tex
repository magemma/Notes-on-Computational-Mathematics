%chktex-file 36
%chktex-file 8
%chktex-file 24
%chktex-file 35
%chktex-file 44
%chktex-file 1
\documentclass[computationalMathematics.tex]{subfiles}

%%%%%%%%%%%%%%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~%%%%%%%%%%%%%%%
\chapter{6th of December 2018}
\chapterauthor{A. Frangioni}
%%%%%%%%%%%%%%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~%%%%%%%%%%%%%%%

\section{Duality}
\recap{
  The KKT-G condition:
  \[
    \nabla f(x) + \sum_{i \in \mathcal{I}} \lambda_i \nabla g_i(x) + \sum_{j \in \mathcal{J}} \mu_j \nabla h_j(x) = 0
  \]
}

We would like to understand what is the function of which this is the gradient.

\begin{definition}[Lagrangian function]
  Let (P) be our minimum problem over $f: \R^n \to \R$. We term \textbf{Lagrangian function} the following:
  \[
    L(x~\lambda,~\mu) = f(x) + \sum_{i \in \mathcal{I}} \lambda_i g_i(x) +\sum_{j \in \mathcal{I}} \mu_j h_j(x)
  \]
\end{definition}

\begin{proposition}
A necessary condition for optimality is that the gradient of the Lagrangian function is $0$.
  Formally, $\nabla L(x; \lambda, \mu) = 0$.
\end{proposition}

A first approach to use the Lagrangian function would be taking $\lambda$ and $\mu$ such that the Langrangian is positive semidefinite.

But this is a too strict requirement, in fact we impose:

\begin{definition}[Critical cone]
  Let us assume $(x,\lambda,\mu)$ satisfies (KKT). We define the \textbf{critical cone} as
       \[
        C(x,~\lambda,~\mu) =
        \left\{ d\in\R^n \,:\,
        %
        \begin{array}{ll}
         \ps{\nabla g_i(x)}{d} = 0 &
         i \in \mathcal{A}(x) \mbox{ s.t. } \lambda^*_i > 0\\
         %
         \ps{\nabla g_i(x)}{d} \leq 0 &
         i \in \mathcal{A}(x) \mbox{ s.t. } \lambda^*_i = 0\\
         %
         \ps{\nabla h_j(x)}{d} = 0 & i \in \mathcal{J}
        \end{array}\right\}
       \]
\end{definition}

\begin{theorem}
Let us assume we have a point $(x,~\lambda,~\mu)$ that satisfies the Karush-Khun-Tucker conditions and satisfies the linear independence of the contraints. If $x$ is local optimum then $d^T \nabla^2_{xx} L(x,~\lambda,~\mu) d \geq 0 ~ \forall\ d \in C(x,~\lambda,~\mu)$.

Informally, if the hypothesis holds, then the Hessian of the Lagrangian function is $\succeq 0$ on the critical cone.
\end{theorem}

\begin{obs}
$(x,~\lambda,~\mu)$ satisfies (KKT) $\wedge~\nabla^2_{xx} L(x,~\lambda,~\mu) \succ 0$ on $C(x,~\lambda,~\mu)$ then $x$ local optimum.
\end{obs}

We would like to say something more about $\lambda$ and $\mu$. Until now we considered the Lagrangian as a function of $x$, but what if we consider the Lagrangian in terms of $\lambda$ and $\mu$?

\section{Lagrangian duality}

\begin{definition}[Lagrangian relaxation]
  Let us consider the Lagrangian function. We term \textbf{Lagrangian relaxation} the function where we fixed $\lambda$ and $\mu$ and minimize on $x$:
  \[
    \psi(\lambda,~\mu) = \min \{L(x,~\lambda,~\mu)~:~x \in \R^n\}
  \]
\end{definition}

The relaxation leads to an unconstrained problem and we learnt how to solve one of those.

This Lagrangian relaxation leads to the definition of \textbf{lagrangian dual} $\psi$.

\begin{property}
  The dual function has the following properties:
  \begin{itemize}
    \item $\psi$ is concave, but $\psi(\lambda, \mu) = - \infty$;
    \item $\psi$ is non differentiable, although $f,~ g_i$ and $h_j$ are;
    \item Let $\bar{x}$ be optimal in $(R_{\lambda, \mu})$, then $[\sum\limits_{i \in \mathcal{I}} \nabla g_i(\bar{x}) + \sum\limits_{j \in \mathcal{J}} \nabla h_i(\bar{x})] \in \partial \psi (\lambda, \mu)$
    \item $\forall \text{ fixed } \lambda \ge 0, \mu, \bar{x} \in X ~ \psi(\lambda, \mu) = \min\limits_x L(x, \lambda, \mu) \le L(\bar{x}, \lambda, \mu) \le f(\bar{x})$
      
      $\psi(\lambda, \mu) =
      \begin{pmatrix}
        \lambda_1 g_1(\bar{x})\\
        \vdots\\
        \lambda_k g_k(\bar{x})\\
        \lambda_1 \mu_1(\bar{x})\\
        \vdots\\
        \lambda_p \mu_p(\bar{x})\\
      \end{pmatrix}$
  is such that $\begin{pmatrix}
        g_1(\bar{x})\\
        \vdots\\
        g_k(\bar{x})\\
        \mu_1(\bar{x})\\
        \vdots\\
        \mu_p(\bar{x})\\
      \end{pmatrix}$ belongs to the supergradient. 

  \end{itemize}
\end{property}

\begin{theorem}[Weak duality]
  $\forall$ fixed $\lambda \in \R^+ \cup \{0\}, \mu \in \R$ such that $\psi(\lambda,~\mu) \leq v(P)$ and let us take any feasible $\bar{x} \in X$ and $g(\bar{x}) \leq 0$, $h(\bar{x}) = 0$.
  
  It can be proved that $\psi(\lambda, \mu) = \min_x L(x, \lambda, \mu) \leq L(\bar{x}, \lambda, \mu) \leq f(\bar{x})$.
\end{theorem}

\begin{proof}
  $L(x, \lambda, \mu) = f(x) + \sum\limits_i \lambda_i g_i(x) + \sum\limits_j \mu_j h_j(x)$.
  Let us assume we have some $\bar{\lambda}, \bar{\mu}, \bar{x}$, where $\bar{x}$ is feasible (aka $g_i(\bar{x}) \le 0$ and $h_i(\bar{x}) = 0$ and $\bar{\lambda} \ge 0$).

  The value of the dual function is

  $\psi(\bar{\lambda}, \bar{\mu}) = \min\limits_x \{ f(x) + \sum\limits_i \lambda_i g_i(x) + \sum\limits_j \mu_j h_j(x) \le f(\bar{x}) + \sum\limits_i \bar{\lambda}_i g_i (\bar{x}) + \cancel{\sum\limits_j \bar{\mu_j} h_j(\bar{x})}$, where the last term is cancelled, since $h_i(\bar{x})=0$.

  On the other hand, $\sum\limits_i \bar{\lambda}_i g_i(x) \le 0$, which implies that $f(x) \le 0$.
\end{proof}

\begin{obs}
This theorem gives us the way to prove that a point is an optimum.
  Let us assume that we found $\lambda_* \le 0$, $x_*$ and $\mu_*$ such that an equality holds: $\psi(\lambda_*, \mu_*) = f(x_*)$. The value of $\psi$ gives us the information about how far we are from the optimum.
  Let us assume we have $\bar{\lambda}$, $\bar{\mu}$ and $\bar{x}$ then
  $\psi(\bar{\lambda}, \bar{\mu}) \le f(\bar{x}) \le \psi(\bar{\lambda}, \bar{\mu}) + \varepsilon$ and this tells that we are far from the optimum of a factor $\varepsilon$.
\end{obs}
If everything in the original function was convex then the Lagrangian is convex and the computations are easy.

At this point we want to find the biggest lower bound and it may be computed since the function is concave.

$\max \{ \, \psi(\, \lambda \,,\, \mu \,)~:~\lambda \in \R^{|\mathcal{I}|}_{+} \;\;,\;\; \mu \in \R^{|\mathcal{J}|} \, \}$

Notice that the constraints on $\lambda$ are very easy, so the problem may be considered somehow uncontrained.

We can use local methods to compute the maximum of this function.

If we are able to compute the gradient of $\psi$ then we have the supergradients of the fucntion $f$.

Is (P) equal to (D)? Yes, provided that everything is convex. In general the Lagrangian gives a lowerbound.

$v(D) \leq v(P)$

\begin{example}
  Let us take a concave objective function $\min\{-x^2~:~0 \le x \le 1\}$, such that its Lagrangian function is $L(x, \lambda) = - \x^2 + \lambda_1 (x-1) -\lambda_2 x$. It goes without saying that the Lagrangian function is unbounded below (upside-down parabola).

  Formally, $\psi(\lambda) = \min\limits_{x \in \R} L(x, \lambda) = - \infty,~\forall \lambda \in \R^2$, which means that the Lagrangian dual is $v(D) = -\infty < v(P) = -1$.
\end{example}

\begin{theorem}
  Let us assume that $f$, $g$ and $h$ are convex, and constraints qualification holds.
  If the problem has an optimum then the value of the primal and the value of the dual are the same.
  
  Formally, $T_X(x_*) D_X (x_*) \Rightarrow v(D) =v(P)$.
\end{theorem}

\begin{proof}
  We are assuming $x_*$ is an optimum, so the necessary conditions hold, hence we have the Karush Khun Tucker conditions, then we can find $(\lambda^*, \mu^*)$ that satisfy the KKT with $x$.

  Then our claim is that $(\lambda^*, \mu^*)$ is an optimal solution of the dual (D) and the value of the dual is equal to the value of the primal.

  $x_*$ is a stationary point for the Lagrangian function, since it satifies the KKT conditions then $x_*$ is exactly the minimum, since the Lagrangian function is convex.
  
 Hence, the value of the dual $v(D) \ge \psi(\lambda-*, \mu_*) = L(x_*, \lambda_*, \mu_*) = f(x_*) = v(P) \ge v(D)$.
\end{proof}

How many solution may $\psi(\lambda, \mu)$ have? In principle many, but what if $f$ is strongly convex, than everything in the Lagrangian is strongly convex, then he solution of $\psi$ is unique and it is also differentiable, bu typically not two times differentiable.
At this point the Lagrangian dual has a single solution and the optimum of the Lagrangian dual corresponds to an optimum for $f$.

We only translated a minimum problem on convex functions to another minimum problem on other convex functions. We will see soon that in some cases this approach is advantageous in others it is not.

\section{Specialized dual}

\subsection{Linead programs}
(P) \;\; $\min \{ \, cx \,:\, Ax \geq b \, \}$

Lagrangian function: $L(x, \lambda) = cx + \lambda (b - Ax) = \lambda b + (c - \lambda A) x$

Dual function:
\[
\psi( \, \lambda \, ) = \min_{x \in \R^n} L(\, x \,,\, \lambda \,) = 
	    \begin{cases}
	     -\infty  & \text{if $c - \lambda A \neq 0$} \\
	     %
	     \lambda b & \text{if $c - \lambda A = 0$} 
        \end{cases}
       \]
Since we can find a minimum only on a function of the second case we have that:

$(D) \;\; \max\ \{ \, \psi(\, \lambda \, ) \,:\, \lambda \geq 0 \, \}
        \equiv \max\ \{ \, \lambda b \,:\, \lambda A = c \;,
                            \; \lambda \geq 0 \, \}$

Since the lagrangian is far from having an unique optimal solution  the dual does not have a unique maximum so the do not match usually.

\subsection{Quadratic programs}

Notice that thwe quadratic case is simpler than the linear case.

(P) \; $\min \big\{ \, \frac{1}{2} \| \, x \, \|_2^2 \,: \, Ax = b \, \big\}$ (linear least-norm solution)

$L( \, x \,,\, \mu \, ) = \frac{1}{2} \| \, x \, \|_2^2 + \mu ( \, Ax - b \, )$, $\nabla_x L = x + \mu A  = 0 \iff x = - \mu A$, which is stricltly convex since $x^2$ is striclty convex.

$\psi(\mu) = \min_{x \in \R^n} L(\, x \,,\, \mu \, ) = L(\, - \mu A \,,\, \mu \, ) =  -\frac{1}{2} \mu^T (A A^T) \mu - \mu b$

Then the Lagrangian dual (D) \; $\max \{-\frac{1}{2} \tr{\mu} (A \tr{A}) \mu - \mu b \,:\, \mu \in \R^m \}$


We can generalize with quadratic functions for general problems: 

Strictly convex QP:~(P)

$\min \big\{ \, \frac{1}{2} x^T Q x + q x \,:\, Ax \geq b \, \big\}$,
        $Q \succ 0$ $\Longrightarrow$
        (D) \; $\max \big\{ \; \lambda b - \frac{1}{2} v^T Q^{-1} v \,:~\lambda A - v = q \,,\, \lambda \geq 0 \; \big\}$
        strong duality $\equiv v(P) = v(D)$ (almost) always holds

\subsection{Conic program}
We can do duals of things that are not quadratic programs. Sometimes we want to have non linear things to be able to draw different shapes.

\begin{definition}[Conic program]
  We term \textbf{conic program} $\min \{cx~:~Ax~\geq_K~b\}$, where $x \geq_K y \equiv x - y \in K$, where $K$ is a convex cone.
\end{definition}

\begin{example}
It is easy to see that the $\ge$ constraints we saw before are a special case of conic program, where the conic is $\R^n_+$.

$-x_1 -2 x_2 \le 2$

$x_1 + x_2 \ge 1$

$2x_1 - x_2 \ge 0$

Let us write $-x_1 -2 x_2 -2 = s_0$, $x_1 + x_2 -1 = s_1$ and $2x_1 - x_2 = s_2$, such that $s_0,s_1,s_2 \ge 0$.

  We have a mapping from $R^n$ (where the variables live) to $\R^m$ (where the constraints live) and $Ax-b \in K$.

  Rather than writing $s_0, s_1, s_2 \ge 0$ we could write $s_0 \ge \sqrt{s_1^2 + s_2^2}$ and this would still be a conic program.
\end{example}

\addpic{0.5}{pics/6dic/1.png}{$x^3 \ge \sqrt{x_1^2 + x_2^2}$ is a convex cone.}{fig:6dic_1}

The idea is to hide the non linear part in the cone, in particular in $\geq_K$.
 Let us see what happens to cones depending on the function.

There are thrww interesting cones:

\begin{itemize}
  \item $K = \R^n_+ \equiv$ sign constraints $\equiv$ Linear Program;
  \item $K = \mathbb{L} = \big\{ \, x \in \R^n \,:\, x_n \geq \sqrt{\sum_{i=1}^{n-1} x_i^2} \, \big\}$ $\equiv$ Second-Order Cone (or Lorentz cone) Program, that generalizes linear programs;
  \item $K = \mathbb{S}_+ = \{ \, A \succeq 0 \, \}$ $\equiv$ ``$\succeq$'' constraints $\equiv$ SemiDefinite Program.
\end{itemize}

Given the problem that looks like linear except for the cone.

\begin{definition}[Conic dual]
Conic dual: (D) $\max \{ \, yb \,:\, yA = c \,,\, y \geq_{K^D} 0 \, \}$, where $K^D = \{ \, z \,:\, \ps{z}{x} \geq 0 \;\; \forall \, x \in K \, \}$ is a dual cone.
\end{definition}

Sometimes constraints qualification does not hold, since the conic program is not linear sometimes.

Explicit form of second order cone program (SOCP) (``explicit data'' $D_i, d_i, p_i, q_i$) $\min \{ cx~:~ \norm{D_i x - d_i}_2 \le p_i x - q_i ~ i=1, \ldots, m\}$.

It collapses to a linear program for $D_i=0$ and $d_i=0$.

It turns out that the dual has just this explicit form:

\[
  \max \{ \sum\limits_{i=1}^m \lambda_i d_i  + \nu_i q_i~:~ \sum\limits_{i=1}^{m}\lambda_i D_i+ \nu_i p_i = c, ~ \norm{\lambda_i}_2 \le \nu_i, ~ i=1, \ldots, m\} 
\]

where the $nu_i$ are the dual variables of the rightmost part, while the $\lambda_i$ are the dual variables of the leftmost part.

We can write the explicit form of semidefinit problems as
$\min \{cx ~:~ \sum\limits_{i=1}^{n} x_i A^i \succeq B\}$, where $A^i, B \in M(k, \R)$.

There is an even mroe general form of duality, that we are going to introduce next.

\section{Fenchel's duality}

\begin{definition}[Fenchel's conjugate]
We denote \textbf{Fenchel's conjugate} of $f$ $f^*(z) = sup_x \{zx - f(x)\}$.
\end{definition}
We can observe that $f^*$ is always convex, even if $f$ is not and it is closed if $f$ is.

The following functions are such that $f^*$ can be computed easily:
\begin{enumerate}
  \item $f(x) = \frac{1}{2} \norm{x}^2_2 \Longrightarrow f^*(z) = \frac{1}{2} \norm{z}^2_2$ (only function s.t.~$f^* = f$);
  \item ${(\norm{\cdot}_1)}^*(z) = \i_{\mathcal{B}_{\infty}(0,1)}( \, z \, )$, ${(\norm{\cdot}_{\infty})}^*(z) = \i_{\mathcal{B}_1(0,1)}( \, z \, )$;
  \item $f(x) = \max \{g_i x - \alpha_i~i \in I\} \Longrightarrow$ $f^*(z) = \min \big\{\sum_{i \in I} \alpha_i \theta_i~:~\sum_{i \in I} g_i \theta_i = z,~\sum_{i \in I} \theta_i = 1~,~\theta_i \geq 0~i \in I \, \big\}$.
\end{enumerate}

\begin{proposition}
  If we are minimizing the sum of two convex functions (P) $\min \{ f(x) + g(x)\}$, this problem is the same of maximizing the sum of ``almost'' the two conjugates: (D) $- \min \{f^*(z) + g^*(-z)\}$.
\end{proposition}
