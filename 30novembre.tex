%chktex-file 36
%chktex-file 8
%chktex-file 24
%chktex-file 35
%chktex-file 44
%chktex-file 1
\documentclass[computationalMathematics.tex]{subfiles}

\begin{document}

%%%%%%%%%%%%%%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~%%%%%%%%%%%%%%%
\section{30th of November 2018 --- A. Frangioni}
%%%%%%%%%%%%%%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~%%%%%%%%%%%%%%%

\subsection{Constrained optimization}
In this lecture we address the problem of finding the \textbf{optimum} of a function in a subset of its domain, called $X$. The term optimum differs from the minimum, because the optimum in that subset may not be a minimum of the whole function.

$f_* = \min \{ \, f(x) \;:\; x \in X \, \}$

\begin{definition}[Local optimum]
  Given a function $f$ and a constraint set $X$, we denote \textbf{local optimum} the point where the function assumes the minimum value inside the set $X$. Formally,
$\min \{f(x)~:~x \in \mathcal{B}(x_*,\varepsilon)~\cap~ X\}$ for some $\varepsilon > 0$.
\end{definition}

Notice that the only points in which the constraint adds some informations are the ones on the boundary, as shown in \Cref{fig:30nov1}

\addpic{0.5}{pics/30nov/1.png}{The red line is level set of the function corresponding to the smallest value that touches the set $X$. The point in the intersection is not a saddle point of the function $f$, altough it is the minimum.}{fig:30nov1}


There are two kinds of contraints:
\begin{description}
  \item[{\sc Fake ones:}] this first kind is such that the minimum of the function lies inside the set $X$, hence there is no need to use the constraints at all;
  \item[{\sc Real ones:}] when the optimal is on the boundary. This is the case of linear functions, because the gradient is constant $\nabla f(x) = c$.
\end{description}

At this point we want to decide if a point on the boundary is an optimum. In this context it is important how the boundary is defined.

\subsubsection{Linear equality constraints}
A constraint of this kind is very simple: it is a subspace, as shown in \Cref{fig:30nov2}.

\addtwopics{0.3}{pics/30nov/eqKKT01.pdf}{0.3}{pics/30nov/eqKKT02.pdf}{Linear constraint and a point on the boundary.}{fig:30nov2}
\addtwopics{0.3}{pics/30nov/eqKKT03.pdf}{0.3}{pics/30nov/eqKKT04.pdf}{The gradient is orthogonal to the level set in that point, when the function is smooth. The same holds for matrix $A$.}{fig:30nov3}
\addtwopics{0.3}{pics/30nov/eqKKT05.pdf}{0.3}{pics/30nov/eqKKT06.pdf}{If we take any other point in the space it has to be orthogonal to $A$.}{fig:30nov4}

$\min\{f(x)~:~Ax = b\}$, where the rank of $A$ counts the number of linearly independent rows.

Let us assume that there are not linearly independent rows in $A$, then or this behaviour is reflected in $B$ or the system does not have any solution.

In the case of presence of linearly dependent columns such columns may be eliminated to ease the computation without loss of information.


The intuition behind what follows is that each linear constraint kills one degree of freedom, formally $det(A_B) \neq 0 \Rightarrow Ax = b \equiv x_B = A_B^{-1}(b - A_N x_N) \Rightarrow$.

        We want to extract a submatrix $A_B$ from $A \in M(m, n, \R)$, such that $A_B \in M(m, \R)$ and then the system induces a partitioning in the variables as well.

$A = [A_B,A_N]$, $x = [x_B,x_N]$, so the system becomes $A_B x_B + A_N x_N =  b$ and (since $A_B$ is non singular) $X_B + \inv{A_B} x_N = \inv{A_B} b$ in other words, given the indepedent variables we can compute the values of the dependent ones and this is a linear operation.

The original optimization problem becomes an optimization problem on a reduced space, formally $\min \{ r(w) = f(Dw+d): w \in \R^{n-m}\}$, where $D = \left[ \begin{array}{c} - A_B^{-1} A_N \\ I \end{array}\right]$ and $d = \left[\begin{array}{c} A_B^{-1} b \\ 0 \end{array}\right]$.
For each point in the smaller space we can compute the function in the larger space.

How can we compute the gradient of $r(w)$? The gradient is $\nabla~r(w) = \tr{D}\nabla~f(Dw +d)$.
The fact that $w^*$ is an optimum implies that $\nabla~r(w^*) = 0$.

$D = \left[ \begin{array}{c} - A_B^{-1} A_N \\ I \end{array}\right]$ then $AD = \left[ A_B, A_N \right] \cdot \left[ \begin{array}{c} - A_B^{-1} A_N \\ I \end{array}\right] = -A_B \cdot \inv{A_B} \cdot A_N + A_N = 0$.

  Now the point is taking a multiple of matrix $A$, finding a feasible $x$ and corresponding $w$ (because there is a bijection), then finding the value $\mu$ that allows the equality.

\begin{theorem}
  Let $Ax=b$ be a linear system and $w$ such that $x = \left[ \inv{A_B} (b - A_N w), w \right]$.
  If $\exists~\mu~\in~\R^m~s.t.~\mu A = \nabla~f(x)$ then $r(w) = \tr{D} \nabla~f(x) = 0$, see \Cref{fig:30nov4}.
  In other words, it is equivalent to find a stationary point x for the original problem $(P)$ or finding the stationary point $w$ for $(R)$.
\end{theorem}

\begin{definition}[Poorman's Karush Kuntaker conditions]
  A point is a good candidate for being a minimum of the constrained problem if and only if it satisfy \textbf{Poorman's KKT conditions}, namely the problem is feasible and that $\exists \mu \in \R^m$ s.t. $\mu A = \nabla f(x)$.
\end{definition}

\begin{theorem}
Let $f$ be a convex function, then KKT conditions are enough for optimality.
\end{theorem}

A very naive explanation of the theorem is that if the function is convex also the restriction is convex and a tationary point of a convex function is a minimum.

Our idea is to characterize the directions we can move along in order to find new points that satisy the constraint.
Formally, $Ax=b$ is our contstraint and we want to move towards $x+d$ and stay in the feasible region.
How? $A(w+d) = b \Leftrightarrow Ax + Ad = b \Leftrightarrow Ad=0$, since $Ax=b$. The only way to move along the constraint is choosing a direction which scalar product with $A$ is $0$, hence $0$ scalar product with the gradient.

From now on we would like to study the behaviour on contrained problems where the constraints are equalities, but inequalities.

In order to do this we need some mathematical background.

\subsubsection{Background for linear inequality contstraints}

\begin{definition}[Tangent cone]
  We call \textbf{tangent cone} of $X$ at $x$ $\mathbf{T_X(x)}=$t.
\[
  \big\{d \in \R^n~:~\exists~ \{z_i \in X\} \to x \;\wedge\;
  \{t_i \geq 0\} \to 0 \mbox{ s.t. } d = \lim\limits_{i \to \infty}
   \frac{z_i - x}{t_i} \big\}
\]
\end{definition}

\addpic{0.3}{pics/30nov/tangentcone01.pdf}{When the boundary has this shape we can move along directions that point inside the constraints. Tangent directions are not allowed.}{fig:30nov4}

\addpic{0.3}{pics/30nov/tangentcone08.pdf}{Geometric representation of tangent cone, which is the region of the space where we can pick the directions. The intuition is to zoom in $x$ and the result of this zooming is a cone.}{fig:30nov5}

\begin{theorem}
  Let $\mathcal{C}$ be a cone, $\forall x \in \mathcal{C}~\alpha x \in \mathcal{C},~\forall \alpha>0$.
\end{theorem}

\begin{theorem}\label{teo:30nov1}
  Given a function $f$, where $x$ is a \textbf{local} optimum $\ps{\nabla f(x)}{d} \geq 0~\forall d \in T_X(x)$.
\end{theorem}

\begin{proof}
  \textbf{Proof by contraddiction:}
  Assume $\exists d \in T_X(x)$ such that $\ps{\nabla f(x)}{d} < 0$, but $x$ is a local optimum.

  By definition $\exists X \supset \{ z_i \} \to x$ and $\{ t_i \} \to 0$ such that $d \stareq \lim\limits_{i \to \infty} \frac{z_i - x}{t_i}$.

  First order Taylor $f(z_i) - f(x) = \ps{\nabla f(x)}{(z_i - x)} + R(z_i - x)$.

  \begin{equation}
    \begin{aligned}
      \lim\limits_{i \to \infty} \frac{f(z_i - x)}{t_i} &= \lim\limits_{i \to \infty} \ps{\nabla f(x)}{\frac{z_i - x}{t_i}} + \frac{R(z_i - x)}{t_i}\\
      &\stareq \ps{\nabla f(x)}{d} + \lim\limits_{i \to \infty} \frac{R(z_i - x)}{t_i}\\
      &\numeq{(1)} \ps{\nabla f(x)}{d}\\ 
      &< 0
    \end{aligned}
  \end{equation}
  Where, $\numeq{(1)}$ follows from $\lim\limits_{i \to \infty} \frac{R(z_i - x)}{t_i} = 0$ by Taylor.
\end{proof}

\begin{obs}
  The optimum of \Cref{teo:30nov1} is global when the function is convex, because in that case $X \subseteq x + T_X(x)$. For a geometric idea see \Cref{fig:30nov5}.
\addpic{0.3}{pics/30nov/tangentcone10.pdf}{Convex function.}{fig:30nov5}
\end{obs}

\begin{obs}
  Notice that the rule  $\ps{\nabla f(x)}{d} \geq 0~\forall d \in T_X(x) \Rightarrow x$ local optimum does not hold. Let us see a counter example: $\min \{ \, x_2 \,:\, x_2 \geq x_1^3 \, \}$, displayed in \Cref{fig:30nov6}.

\addpic{0.3}{pics/30nov/tangentcone13.pdf}{Let us suppose we pick the direction towards the left part of the function in the saddle point. That direction is promising and actually the value of the function decreases. In this case the problem is that the contraint is not convex.}{fig:30nov6}
\end{obs}

Now we need a more manageable object for $T_X(x)$.

\begin{definition}[Cone of feasible directions]~\\
  Intuitively, we are in $x$ and we want to find al directions \textbf{feasible cone} such that there exist small but not $0$ steps such that all the points on this direction are feasible.
  Formally, a \textbf{feasible cone} is $F_X(x) = \{ d \in \R^n~:~ \exists \bar{\varepsilon} > 0 \text{ such that } x + \varepsilon d \in X, ~ \forall \varepsilon \in [0, \bar{\varepsilon}]\}$.
\end{definition}

\begin{proposition}
The properties of such cone are:
  \begin{enumerate}
    \item $T_X$ closed, $F_X$ in general not (hence the cone of feasible directions is the tangent cone minus the tangent directions);
    \item $cl(F_X) \subseteq T_X$, where $cl(F_X)$ is the closure of the cone of feasible directions;
    \item If $X$ convex then the cones coincide: $T_X$ and $F_X$ convex and $cl \, F_X = T_X$.
  \end{enumerate}
\end{proposition}

We are now interested in finding a better characterization of the cone fo feasible directions, hence we introduce a new characterization fo the set of constraints $X$.

\begin{description}
  \item[{\sc First representation:}]
    \[
  X = \{x \in \R^n \,:\, g_i(x) \leq 0 \;\; i \in \mathcal{I},~h_j(x) = 0 \;\; j \in \mathcal{J} \, \} 
    \]
 where $\mathcal{I}$ is the set of inequality constraints and $\mathcal{J}$ is the set of equality constraints;
  \item[{\sc Second representation:}]
    \[
      X = \{ \, x \in \R^n \,:\, G(x) \leq 0 \,,\, H(x) = 0\}
    \]
    where $G = {[g_i(x)]}_{i \in \mathcal{I}} : \R^n \to \R^{|\mathcal{I}|}$ and $H = {[h_i(x)]}_{i \in \mathcal{J}} : \R^n \to \R^{|\mathcal{J}|}$;
  \item[{\sc Third representation:}] (hiding equalities)
    \[
      X = \{x \in \R^n : g_i(x) \leq 0~i \in \mathcal{I},~h_j(x) \le 0~ \wedge~h_j(x) \ge 0~j \in \mathcal{J}\} 
    \]
  \item[{\sc Fourth representation:}] (hiding inequalities into a single function)
    \[
  X = \{x \in \R^n \,:\,g(x) = \max \{ \, g_i(x) \,:\, i \in \mathcal{I} \, \} \leq 0~i \in \mathcal{I},~h_j(x) = 0 ~ \in \mathcal{J}\} 
    \]
  \end{description}

\begin{definition}[Active constraints]
  We term \textbf{active constraints} at $x \in X$ the following set
  \[
    \mathcal{A}(x) = \{i \in \mathcal{I}~:~g_i(x) = 0\} \subseteq \mathcal{I}
  \]
\end{definition}

Let us introduce some useful notation on the subject: let $\mathcal{B} \subseteq \mathcal{I}$ a subset of indices.

We denote $G_{\mathcal{B}} = {[g_i(x)]}_{i \in \mathcal{B}} : \R^n \to \R^{|\mathcal{B}|}$ the corresponding set of inequalities.


\begin{definition}[First-order feasible direction cone]
  We term \textbf{First-order feasible direction cone at $x \in X$}: 
  
  \[
    D_X(x) =\{d \in \R^n~:~\ps{\nabla g_i(x)}{d} \leq 0~i \in \mathcal{A}(x)~\ps{\nabla h_j(x)}{d} = 0~j \in \mathcal{J}\} = \{d \in \R^n :(J G_{\mathcal{A}(x)}(x)) d  \leq 0,~(J H(x)) d = 0\}
  \]
  Intuitively, the fact that we are looking at the active set means that we are zooming very close to $0$.

  In this cone we require that all the directions inside it have a negative scalar product with the gradient of the contraints.
\end{definition}

A visual example of a first order feasible direction cone is displayed in \Cref{fig:30nov6}.

\addpic{0.3}{pics/30nov/tangentcone18.pdf}{The first-order feasible direction cone is made of those directions that are orthogonal to the gradient of the constraints $g_1(x)$ and $g_2(x)$ in $x$.}{fig:30nov6}

\begin{proposition}
The tangent cone is a subset of the first-order feasible direction cone. Formally, $T_X(x) \subseteq D_X(x)$.
\end{proposition}

We would like the first-order feasible direction cone to be exactly equal to the tangent cone and this is almost always true, except for some pathological cases.

\begin{example}
  Let our minimum problem be $\min \{\ldots~:~{x_1}^2 + {(x_2-1)}^2 - 1 \leq 0,~x_2 \leq 0\}$.

  The plot of such functions is shown in \Cref{fig:30nov7}.

  \addpic{0.4}{pics/30nov/tangentcone21.pdf}{The circle represents the quadrati constraint, while the semi-plane represents the first degree constraint.}{fig:30nov7}

  Our claim is that the only feasible point is $X =\{ x = [0,0]\}$.

  The only feasible direction is $0$, hence cone of feasible direction and the tangent cone are the singleton $\{[0,0]\}$.

  On the other hand, the set of directions that have non-negative scalar product with both $g_1$ and $g_2$ are all the $x$ axis.
\end{example}

We would like to ensure we are not in one of these pathological cases and to do this we introduce some conditions.

\begin{proposition}
The following holds:
  \begin{description}
    \item[{\sc Affine constraints (AffC):}] Let $g_i$ and $h_j$ be affine constraints. Then, $\forall~i \in \mathcal{I}$ and $j \in \mathcal{J}~ T_X(x) = D_X(x)~\forall x \in X$.
    \item[{\sc Slater's condition (SlaC):}] Let $g_i$ convex $\forall ~i \in \mathcal{I}$ and let $h_j$ affine $\forall~j \in \mathcal{J}$ $\exists~\bar{x} \in X$ s.t. $g_i(\bar{x}) < 0~\forall~i \in \mathcal{I}$. Then $T_X(x) = D_X(x)~\forall \, x \in X$;
    \item[{\sc Linear independence (LinI):}] $\bar{x} \in X~\wedge$ the vectors $\{\nabla g_i(\bar{x})~:~i \in \mathcal{A}(\bar{x})\} \cup~\{\nabla h_j(\bar{x})~:~j \in \mathcal{J}\}$ linearly independent $\Longrightarrow T_ X(\bar{x}) = D_X(\bar{x})$.
      Among all these conditions this is the only local one.
   \end{description}
\end{proposition}

It goes without saying that we cannot check all the directions in order to exclude the nasty pathological cases.

\begin{definition}[Dual cone]
  Let $D_X$ be a \textbf{polyhedral cone} $\mathcal{C} = \{d \in \R^n~:~Ad \leq 0\}$, for some $A \in \R^{k \times n}$.
  
  We term \textbf{dual cone} $\mathcal{C}^* = \{c = \sum\limits_{i = 1}^k \lambda_i A_i~:~\lambda \geq 0 \, \}$.
\end{definition}

\begin{lemma}[Farka's lemma]
Intuitively, this lemma says that pick a vector: either it belongs to the dual cone or there exists a vector in the polyhedral cone which has a negative scalar product with it.

Equivalently, either $c \in \mathcal{C}^*$ or $c \notin \mathcal{C}^*$.

More formally, either $\exists \, \lambda \geq 0$ s.t.~$c = \sum_{i = 1}^k \lambda_i A_i$ or $\exists \, d$ s.t.~$Ad \leq 0 \wedge \ps{c}{d} > 0$.
\end{lemma}

\begin{theorem}[Karush-Kuhn-Tucker conditions]
Let us assume that we found an optimal solution $x_*$ and the constraints qualification holds.

Then $\exists \lambda \in \R^{|\mathcal{I}|}_{+}$ and $\mu \in \R^{|\mathcal{I}|}$ such that
    \[
    \nabla f(x) + \sum_{i \in \mathcal{A}(x)} \lambda_i \nabla g_i(x) + \sum_{j \in \mathcal{J}} \mu_j \nabla h_j(x) = 0
  \]
\end{theorem}

It is interesting to notice that we did not impose $\mu \ge 0$.
Let us take an equality constraint $h_j(x) = 0$. This is equivalent to write $h_j(x) \le 0 ~ \wedge h_j(x) \ge 0$, thus leading to two different multipliers, say $\lambda_j^{+}$ and $\lambda_j^{-}$.

The term of the sum concerning $h_j$ looks like this $\lambda_j^+ \nabla h_j(x_*) - \lambda_j^-\nabla h_j(x_*) = (\lambda_j^+ - \lambda_j^-) \cdot \nabla h_j(x_*)$, where both $\lambda_j^+$ and $\lambda_j^-$ are $\ge 0$, hence their difference (denoted by $\mu_j$) may be either positive or negative.

\begin{proposition}
The Karush-Kuhn-Tucker conditions are also written as:

  \begin{description}
    \item[{\sc Feasibility:}]$x \in X \equiv g_i(x) \leq 0 \;\; i \in \mathcal{I},~  h_j(x) = 0 \;\; j \in \mathcal{J}$
    \item[{\sc KKT-G:}] $\nabla f(x) + \sum\limits_{i \in \mathcal{I}} \lambda_i \nabla g_i(x) + \sum\limits_{j \in \mathcal{J}} \mu_j \nabla h_j(x) = 0$
    \item[{\sc Complementarity Slackness:}] $\sum\limits_{i \in \mathcal{I}} \lambda_i g_i(x) = 0$
  \end{description}
  where the second and the third equations formalize the definition of KKT, where the terms of the first sum should be summed only if their contraints are active.
\end{proposition}

\begin{proposition}
  Let (P) be a convex problem. In this case, if the Karush-Kuhn-Tucker conditions hold then $x$ is a global optimum.
\end{proposition}

\end{document}
